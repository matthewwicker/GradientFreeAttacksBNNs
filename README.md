# Gradient-Free Adversarial Attacks on Bayesian Neural Networks (AABI 2021)

This is the code repository for the paper 'Gradient-Free Attacks on Bayesian Neural Networks' that was accepted to Advances in Approximate Bayesian Inference 2021. The preliminary and rough framework that is used for inference on DNN architectures has been updated and is 'maintained' in a rough since at github.com/matthewwicker/deepbayes for issues regarding the framework please contact matthew (dot) wicker (at) cs.ox.ac.uk

Reference Materials for further understanding this work:

* Paper link: _to appear later_
* Video presentation: _to appear later_

Local draft of the paper can be found [here](https://github.com/matthewwicker/GradientFreeAttacksBNNs/blob/master/repo_resources/Draft-AABI.pdf)


![alt text](https://github.com/matthewwicker/GradientFreeAttacksBNNs/blob/master/repo_resources/readmefig.png)

Example Figure: Robust Accuracy on the MNIST dataset for each approximate Bayesian inference method against PGD, PGD with ZOO approximate gradients, PGD with BPDA approximate gradients, GA. We observe that in all cases GA outperforms other methods.

